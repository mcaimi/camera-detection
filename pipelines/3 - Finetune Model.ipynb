{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f327ca0a-82a3-4053-be69-c348d0624ee7",
   "metadata": {},
   "source": [
    "# STAGE III - Run Model Training/Finetuning and Convert Resulting Checkpoint to ONNX\n",
    "\n",
    "We now finetune the model with the previously downloaded dataset and then, once the process is finished, the resulting checkpoint is saved in ONNX format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e6665-159b-4509-b27a-a3b239b4442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f6121b-b478-4ff5-9a1a-d27417fcbcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "try:\n",
    "    import os\n",
    "    import torch\n",
    "    import torch.cuda as tc\n",
    "    import ultralytics\n",
    "except Exception as e:\n",
    "    print(f\"Caught Exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dab8b65-abb5-49b5-b427-c80bb4f5594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect accelerator\n",
    "def detectAccelerator() -> (str, torch.dtype):\n",
    "    accelerator = \"cpu\"\n",
    "    dtype = torch.float32\n",
    "\n",
    "    # ensure the apple mps backend is loaded and hardware initialized\n",
    "    if tc.is_available():\n",
    "        print(\"CUDA Accelerator Available\")\n",
    "        accelerator = \"cuda\"\n",
    "        dtype = torch.float16\n",
    "        !nvidia-smi\n",
    "\n",
    "    # return\n",
    "    return (accelerator, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b228ad-2768-4b9d-bd90-8624565b5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare global setting variables\n",
    "PERSISTENCE_DIR: str = os.environ.get('PERSISTENCE_DIR')\n",
    "ULTRALYTICS_DIR = os.path.join(PERSISTENCE_DIR, \"ultralytics\")\n",
    "CHECKPOINT_NAME: str = os.environ.get(\"YOLO_CHECKPOINT\")\n",
    "CHECKPOINT_CONFIG: str = os.environ.get(\"YOLO_CONFIG\")\n",
    "YOLO_MODEL_PATH: str = os.path.join(ULTRALYTICS_DIR, \"Ultralytics/YOLO11\")\n",
    "YOLO_ORIGINAL_MODEL: str = \"/\".join((YOLO_MODEL_PATH, CHECKPOINT_NAME))\n",
    "DATASET_NAME: str = \"mario\"\n",
    "TRAINING_DATASET_PATH: str = os.path.join(PERSISTENCE_DIR, \"data\")\n",
    "\n",
    "print(f\"Using YOLO Model Original Checkpoint at: {YOLO_ORIGINAL_MODEL}\")\n",
    "print(f\"Dataset '{DATASET_NAME}' will be loaded from {TRAINING_DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e3a6b-2463-45b6-a61a-a8226288bfce",
   "metadata": {},
   "source": [
    "## Setup the training job\n",
    "\n",
    "Make sure the checkpoint is available and load that into the available accelerator (CPU/GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d45be-ca8c-4ef0-bd85-3ca8a3d9bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "JOB = os.environ.get(\"JOB_TYPE\", \"detect\")\n",
    "RUN_NAME = os.environ.get(\"JOB_NAME\", \"train\")\n",
    "CHECKPOINT = \"last.pt\"\n",
    "EPOCHS = int(os.environ.get(\"EPOCHS\", \"20\"))\n",
    "LR = 1e-4\n",
    "IMG_SIZE = int(os.environ.get(\"IMG_SIZE\", \"640\"))\n",
    "BATCH = int(os.environ.get(\"BATCH\", \"2\"))\n",
    "OPTIMIZER = os.environ.get(\"OPTIMIZER\", \"AdamW\")\n",
    "AUGMENT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa288d1-9b58-4289-9ad7-8a3357a267d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ff75f-aafa-4614-89e7-e74bfbcca5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect accelerator\n",
    "accelerator, dtype = detectAccelerator()\n",
    "\n",
    "# load checkpoint in memory\n",
    "print(f\"Loading checkpoint {YOLO_ORIGINAL_MODEL}...\")\n",
    "yolo_model = ultralytics.YOLO(CHECKPOINT_CONFIG).load(YOLO_ORIGINAL_MODEL)\n",
    "yolo_model.to(accelerator)\n",
    "resume = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b307a24-0ce6-45eb-8749-852c9f0da838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training!\n",
    "# this does not seem to when run in a pipeline.\n",
    "#ultralytics.settings.update({'datasets_dir': TRAINING_DATASET_PATH})\n",
    "# UGLY workaround: copy datasets to default path\n",
    "!mkdir -p /opt/app-root/src/datasets\n",
    "!cp -r $TRAINING_DATASET_PATH/mario /opt/app-root/src/datasets/\n",
    "\n",
    "# train\n",
    "yolo_model.train(data=f\"{TRAINING_DATASET_PATH}/{DATASET_NAME}/mario.yaml\",\n",
    "                 epochs=EPOCHS, lr0=LR, imgsz=IMG_SIZE, batch=BATCH,\n",
    "                 resume=resume, optimizer=OPTIMIZER, augment=AUGMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a8e9e-8e67-48dc-82ac-e89d7202f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert checkpoint\n",
    "yolo_model.export(format=\"onnx\")\n",
    "\n",
    "# make sure checkpoint exists\n",
    "latest_checkpoint: str = f\"runs/{JOB}/{RUN_NAME}/weights/best.onnx\"\n",
    "\n",
    "# validate\n",
    "if not os.path.exists(latest_checkpoint):\n",
    "    raise Exception(f\"Checkpoint {latest_checkpoint} not found in filesystem\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
