# PIPELINE DEFINITION
# Name: yolo-custom-training-pipeline
# Description: Dense Neural Network CNN Image Detector based on YOLO
# Inputs:
#    author_name: str
#    cluster_domain: str
#    data_mount_path: str
#    dataset_name: str
#    huggingface_repo: str
#    hyperparameters: dict
#    model_name: str
#    prod_flag: bool
#    s3_deployment_name: str
#    s3_region: str
#    version: str
components:
  comp-convert-model:
    executorLabel: exec-convert-model
    inputDefinitions:
      artifacts:
        finetuned_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
      parameters:
        data_dir:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        onnx_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-fetch-data:
    executorLabel: exec-fetch-data
    inputDefinitions:
      parameters:
        dataset_name:
          parameterType: STRING
        version:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-fetch-model:
    executorLabel: exec-fetch-model
    inputDefinitions:
      parameters:
        hyperparameters:
          parameterType: STRUCT
        model_name:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        original_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-push-to-model-registry:
    executorLabel: exec-push-to-model-registry
    inputDefinitions:
      parameters:
        author_name:
          parameterType: STRING
        cluster_domain:
          parameterType: STRING
        data_path:
          parameterType: STRING
        model_name:
          parameterType: STRING
        s3_deployment_name:
          parameterType: STRING
        s3_region:
          parameterType: STRING
        version:
          parameterType: STRING
  comp-train-model:
    executorLabel: exec-train-model
    inputDefinitions:
      artifacts:
        dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        original_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
      parameters:
        data_mount_path:
          parameterType: STRING
        hyperparameters:
          parameterType: STRUCT
    outputDefinitions:
      artifacts:
        finetuned_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        training_metrics:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-unzip-dataset:
    executorLabel: exec-unzip-dataset
    inputDefinitions:
      artifacts:
        dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        data_dir:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        dataset_properties:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-unzip-model:
    executorLabel: exec-unzip-model
    inputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
      parameters:
        data_dir:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        model_properties:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-convert-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - convert_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.2'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef convert_model(\n    data_dir: str,\n    finetuned_model: Input[Model],\n\
          \    onnx_model: Output[Model],\n):\n    from zipfile import ZipFile\n \
          \   from pathlib import PosixPath\n    import os\n\n    # Unzip source model\n\
          \    workdir: str = \"/\".join((data_dir, \"onnx\"))\n    os.makedirs(workdir,\
          \ exist_ok=True)\n    with ZipFile(finetuned_model.path, 'r') as compressed_model:\n\
          \        compressed_model.extractall(workdir)\n\n    # convert & save model\
          \ to onnx\n    from ultralytics import YOLO\n    weights_file: str = max(PosixPath(workdir).rglob(\"\
          last.pt\"), key=os.path.getmtime)\n    torch_model = YOLO(weights_file)\n\
          \    torch_model.export(format=\"onnx\")\n\n    # save model to s3\n   \
          \ onnx_model._set_path(onnx_model.path + \"-onnx.zip\")\n    last_file:\
          \ str = max(PosixPath(workdir).rglob(\"*.onnx\"), key=os.path.getmtime)\n\
          \n    # zip & store\n    import zipfile\n    with zipfile.ZipFile(onnx_model.path,\
          \ \"w\", zipfile.ZIP_DEFLATED) as zip_file:\n        zip_file.write(last_file)\n\
          \n"
        image: quay.io/marcocaimi/ultralytics-onnx:latest
        resources:
          cpuLimit: 8.0
          memoryLimit: 24.0
          resourceCpuLimit: '8'
          resourceMemoryLimit: 24G
    exec-fetch-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - fetch_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.2'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'kagglehub'\
          \ 'python-dotenv' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef fetch_data(\n    dataset_name: str,\n    version: str,\n    dataset:\
          \ Output[Dataset]\n):\n    # import libs\n    import os\n    try:\n    \
          \    import kagglehub\n    except Exception as e:\n        print(f\"Caught\
          \ exception {e}\")\n\n    # Check environment\n    KG_USER = os.getenv('KAGGLE_USERNAME')\n\
          \    KG_PASS = os.getenv('KAGGLE_KEY')\n    KG_PATH = os.getenv('KAGGLEHUB_CACHE')\n\
          \n    print(f\"Connecting to Kaggle as {KG_USER} with API Key {KG_PASS},\
          \ save artifacts to {KG_PATH}\")\n\n    # download dataset from kaggle now\n\
          \    DATASET_NAME: str = dataset_name\n    TRAINING_DATASET_PATH: str =\
          \ KG_PATH\n\n    # get the dataset\n    print(f\"Dataset '{DATASET_NAME}'\
          \ will be downloaded to {TRAINING_DATASET_PATH}\")\n    dspath: str = kagglehub.dataset_download(DATASET_NAME)\n\
          \    print(f\"Dataset available @{dspath}\")\n\n    # zip the dataset\n\
          \    import zipfile\n    from pathlib import Path\n\n    # save output dataset\
          \ to S3\n    dataset.path += \".zip\"\n    srcdir = Path(dspath)\n\n   \
          \ with zipfile.ZipFile(dataset.path, \"w\", zipfile.ZIP_DEFLATED) as zip_file:\n\
          \        for entry in srcdir.rglob(\"*\"):\n            zip_file.write(entry,\
          \ entry.relative_to(srcdir))\n\n"
        image: python:3.11
    exec-fetch-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - fetch_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.2'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'huggingface_hub'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef fetch_model(\n    model_name: str,\n    hyperparameters: dict,\n\
          \    original_model: Output[Model],\n):\n    try:\n        import os\n \
          \       import zipfile\n        from pathlib import Path\n        import\
          \ huggingface_hub as hf\n    except Exception as e:\n        raise e\n\n\
          \    HF_TOKEN: str = os.getenv(\"HF_TOKEN\")\n\n    # Download model checkpoint\
          \ from HuggingFace repositories\n    yolo_path: str = \"/\".join((\"/tmp/\"\
          , model_name))\n    os.makedirs(yolo_path, exist_ok=True)\n\n    print(f\"\
          Downloading model checkpoint: {model_name}\")\n    model_path = hf.snapshot_download(repo_id=model_name,\n\
          \                                    allow_patterns=hyperparameters.get(\"\
          checkpoint\"),\n                                    revision=\"main\",\n\
          \                                    token=HF_TOKEN,\n                 \
          \                   local_dir=yolo_path)\n\n    # save output dataset to\
          \ S3\n    original_model._set_path(original_model.path + \".zip\")\n   \
          \ srcdir = Path(yolo_path)\n\n    with zipfile.ZipFile(original_model.path,\
          \ \"w\", zipfile.ZIP_DEFLATED) as zip_file:\n        for entry in srcdir.rglob(\"\
          *\"):\n            zip_file.write(entry, entry.relative_to(srcdir))\n\n"
        image: python:3.11
    exec-push-to-model-registry:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - push_to_model_registry
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.2'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pip==24.2'\
          \ 'setuptools==74.1.3' 'boto3==1.36.12' 'model-registry' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef push_to_model_registry(\n    model_name: str,\n    version: str,\n\
          \    cluster_domain: str,\n    s3_deployment_name: str,\n    s3_region:\
          \ str,\n    author_name: str,\n    data_path: str,\n):\n    from model_registry\
          \ import ModelRegistry\n    from model_registry.utils import S3Params\n\
          \    from model_registry.exceptions import StoreError\n    from pathlib\
          \ import PosixPath\n    import os\n\n    # environment setup\n    from os\
          \ import environ\n    environ[\"KF_PIPELINES_SA_TOKEN_PATH\"] = \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\
          \n\n    # Set up the model registry connection\n    s3_deployment = s3_deployment_name\n\
          \    model_registry_url = f\"https://registry-rest.{cluster_domain}\"\n\
          \    minio_endpoint = f\"https://{s3_deployment}.{cluster_domain}\"\n\n\
          \    # registry connection object\n    registry = ModelRegistry(server_address=model_registry_url,\
          \ port=443, author=author_name, is_secure=False)\n\n    # Model details\
          \ we want to register\n    registered_model_name = model_name\n    s3_model_bucket\
          \ = \"models\"\n    s3_model_prefix = f\"{s3_model_bucket}/{registered_model_name}\"\
          \n    version = version\n\n    # remote S3 paths\n    s3_region = s3_region,\n\
          \    s3_onnx = f\"{s3_model_prefix}/onnx/{registered_model_name}\"\n   \
          \ s3_torch = f\"{s3_model_prefix}/torch/{registered_model_name}\"\n\n  \
          \  # upload parameters for s3 connections\n    s3_upload_params_onnx = S3Params(\n\
          \        bucket_name=os.environ.get('AWS_S3_BUCKET'),\n        s3_prefix=f\"\
          {s3_onnx}/{version}\",\n    )\n    s3_upload_params_torch = S3Params(\n\
          \        bucket_name=os.environ.get('AWS_S3_BUCKET'),\n        s3_prefix=f\"\
          {s3_torch}/{version}\",\n    )\n\n    # artifact update function\n    def\
          \ update_artifact(model_name, model_version, new_uri, storage_path):\n \
          \       artifact = registry.get_model_artifact(model_name, model_version)\n\
          \        print(f\"Got Artifact {artifact.name} with ID: {artifact.id}\\\
          n Current URI: {artifact.uri}\\n Updating with URI: {new_uri}\\n Current\
          \ StoragePath: {artifact.storage_path}\")\n        artifact.uri = new_uri\n\
          \        artifact.storage_path = storage_path\n        registry.update(artifact)\n\
          \n    # upload function\n    def register(model_name, data_path,\n     \
          \            model_format_name, author, model_format_version,\n        \
          \         model_version, storage_path, description,\n                 metadata,\
          \ upload_parms):\n        try:\n            # register onnx model\n    \
          \        registered_model = registry.upload_artifact_and_register_model(\n\
          \                name=model_name,\n                model_files_path=data_path,\n\
          \                model_format_name=model_format_name,\n                author=author,\n\
          \                model_format_version=model_format_version,\n          \
          \      version=model_version,\n                storage_path=storage_path,\n\
          \                description=description,\n                metadata=metadata,\n\
          \                upload_params=upload_parms\n            )\n           \
          \ print(f\"'{model_name}' version '{model_version}'\\n URL: https://rhods-dashboard-redhat-ods-applications.{cluster_domain}/modelRegistry/registry/registeredModels/1/versions/{registry.get_model_version(model_name,\
          \ model_version).id}/details\")\n        except StoreError:\n          \
          \  stored_version = registry.get_model_version(registered_model_name, f\"\
          {version}-onnx\")\n            print(f\"Model version {stored_version.name}-{stored_version.id}\
          \ already exists: Updating URI...\")\n            new_uri = f\"s3://{storage_path}?endpoint={minio_endpoint}&defaultRegion={s3_region}\"\
          \n            update_artifact(model_name, model_version, new_uri, storage_path)\n\
          \n    # get & unzip checkpoints from pipeline storage\n    torch_file: str\
          \ = max(PosixPath(data_path).rglob(\"last.pt\"), key=os.path.getmtime)\n\
          \    onnx_file: str = max(PosixPath(data_path).rglob(\"last.onnx\"), key=os.path.getmtime)\n\
          \n    # data to register in the model registry\n    models = [\n       \
          \ {\n            \"model_name\": registered_model_name,\n            \"\
          data_path\": onnx_file,\n            \"author\": author_name,\n        \
          \    \"model_format_name\": \"onnx\",\n            \"model_format_version\"\
          : \"1\",\n            \"model_version\": f\"{version}-onnx\",\n        \
          \    \"storage_path\": f\"{s3_model_bucket}/{s3_onnx}\",\n            \"\
          description\": \"Dense Neural Network trained on music data (ONNX)\",\n\
          \            \"metadata\": {\n                        \"format\": \"onnx\"\
          ,\n                        \"license\": \"apache-2.0\"\n               \
          \     },\n            \"upload_parms\": s3_upload_params_onnx\n        },\n\
          \        {\n            \"model_name\": registered_model_name,\n       \
          \     \"data_path\": torch_file,\n            \"author\": author_name,\n\
          \            \"model_format_name\": \"torch\",\n            \"model_format_version\"\
          : \"1\",\n            \"model_version\": f\"{version}-torch\",\n       \
          \     \"storage_path\": f\"{s3_model_bucket}/{s3_torch}\",\n           \
          \ \"description\": \"Dense Neural Network trained on music data (TORCH)\"\
          ,\n            \"metadata\": {\n                        \"format\": \"torch\"\
          ,\n                        \"license\": \"apache-2.0\"\n               \
          \     },\n            \"upload_parms\": s3_upload_params_torch\n       \
          \ }\n    ]\n\n    # register models\n    for model in models:\n        print(f\"\
          Registering: {model.get('model_version')}...\")\n        register(model_name=model.get('model_name'),\n\
          \                 data_path=model.get('data_path'),\n                 model_format_name=model.get('model_format_name'),\n\
          \                 author=model.get('author'),\n                 model_format_version=model.get('model_format_version'),\n\
          \                 model_version=model.get('model_version'),\n          \
          \       storage_path=model.get('storage_path'),\n                 description=model.get('description'),\n\
          \                 metadata=model.get('metadata'),\n                 upload_parms=model.get('upload_parms'))\n\
          \n    print(\"Model registered successfully\")\n\n"
        image: python:3.11
    exec-train-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.2'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_model(\n    original_model: Input[Model],\n    dataset:\
          \ Input[Dataset],\n    hyperparameters: dict,\n    data_mount_path: str,\n\
          \    finetuned_model: Output[Model],\n    training_metrics: Output[Artifact],\n\
          ):\n    import ultralytics\n    import yaml\n    import json\n    import\
          \ os\n    import torch.cuda as tc\n    import pprint\n    from pathlib import\
          \ PosixPath\n\n    # Training Parameters\n    JOB = hyperparameters.get(\"\
          job\")\n    RUN_NAME = hyperparameters.get(\"run_name\")\n    TRAINING_CONFIG\
          \ = hyperparameters.get(\"training_job_descriptor\")\n    CHECKPOINT = hyperparameters.get(\"\
          checkpoint\")\n    EPOCHS = hyperparameters.get(\"epochs\")\n    LR = hyperparameters.get(\"\
          learning_rate\")\n    IMG_SIZE = hyperparameters.get(\"img_size\")\n   \
          \ BATCH = hyperparameters.get(\"batch\")\n    OPTIMIZER = hyperparameters.get(\"\
          optimizer\")\n    AUGMENT = hyperparameters.get(\"augment\")\n\n    # detect\
          \ device\n    device = \"cpu\"\n    if tc.is_available():\n        device\
          \ = \"cuda\"\n\n    cp: str = f\"{data_mount_path}/{CHECKPOINT}\"\n    tc:\
          \ str = f\"{data_mount_path}/{TRAINING_CONFIG}\"\n    print(f\"DEVICE:\\\
          n Training model {cp} on {device}\")\n\n    # load model\n    yolo_model\
          \ = ultralytics.YOLO(cp)\n    yolo_model.to(device)\n\n    # fix training\
          \ descriptor\n    with open(tc, \"r\") as training_descriptor_r:\n     \
          \   training_parms = yaml.safe_load(training_descriptor_r)\n    # update\
          \ base path\n    training_parms[\"path\"] = os.path.dirname(tc)\n    # dump\
          \ parms\n    pprint.pprint(training_parms)\n    # write descriptor back\n\
          \    with open(tc, \"w\") as training_descriptor_w:\n        yaml.dump(training_parms,\
          \ training_descriptor_w)\n\n    # fix run_dir path\n    with open(\"/.config/Ultralytics/settings.json\"\
          , \"r\") as yolo_settings:\n        ys = json.load(yolo_settings)\n    ys[\"\
          runs_dir\"] = f\"{data_mount_path}/runs/{JOB}/{RUN_NAME}\"\n    ys[\"datasets_dir\"\
          ] = f\"{data_mount_path}/datasets/{JOB}/{RUN_NAME}\"\n    ys[\"weights_dir\"\
          ] = f\"{data_mount_path}/weights/{JOB}/{RUN_NAME}\"\n    pprint.pprint(ys)\n\
          \    with open(\"/.config/Ultralytics/settings.json\", \"w\") as yolo_settings:\n\
          \        json.dump(ys, yolo_settings)\n\n    # start training!\n    #yolo_model.train(data=tc,\n\
          \    #                 epochs=EPOCHS, lr0=LR, imgsz=IMG_SIZE, batch=BATCH,\n\
          \    #                 resume=False, optimizer=OPTIMIZER, augment=AUGMENT,\n\
          \    #                 project=data_mount_path)\n\n    # validate\n    #training_metrics\
          \ = yolo_model.val()\n\n    # save model to s3\n    finetuned_model._set_path(finetuned_model.path\
          \ + \".zip\")\n    last_file: str = max(PosixPath(data_mount_path).rglob(\"\
          last.pt\"), key=os.path.getmtime)\n\n    # zip & store\n    import zipfile\n\
          \    with zipfile.ZipFile(finetuned_model.path, \"w\", zipfile.ZIP_DEFLATED)\
          \ as zip_file:\n        zip_file.write(last_file)\n\n"
        image: ultralytics/ultralytics:latest
        resources:
          cpuLimit: 8.0
          memoryLimit: 24.0
          resourceCpuLimit: '8'
          resourceMemoryLimit: 24G
    exec-unzip-dataset:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - unzip_dataset
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.2'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef unzip_dataset(\n    data_dir: str,\n    dataset: Input[Dataset],\n\
          \    dataset_properties: Output[Artifact]\n):\n    # import zipfile lib\n\
          \    import json\n    from pathlib import PosixPath\n    from zipfile import\
          \ ZipFile\n\n    with ZipFile(dataset.path, 'r') as compressed_dataset:\n\
          \        compressed_dataset.extractall(data_dir)\n\n    # save dataset properties\n\
          \    properties = {\n        \"dataset_filename\": dataset.path,\n     \
          \   \"number_of_elements\": len(list(PosixPath(data_dir).rglob(\"*\")))\n\
          \    }\n\n    dataset_properties.path += \".json\"\n    with open(dataset_properties.path,\
          \ \"w\") as artifact_dump:\n        json.dump(properties, artifact_dump)\n\
          \n"
        image: python:3.11
    exec-unzip-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - unzip_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.2'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef unzip_model(\n    data_dir: str,\n    model: Input[Model],\n\
          \    model_properties: Output[Artifact]\n):\n    # import zipfile lib\n\
          \    import json\n    import os\n    from pathlib import PosixPath\n   \
          \ from zipfile import ZipFile\n\n    with ZipFile(model.path, 'r') as compressed_model:\n\
          \        compressed_model.extractall(data_dir)\n\n    # save dataset properties\n\
          \    properties = {\n        \"model_filename\": model.path,\n        \"\
          model_architecture\": \"YOLOv11\",\n        \"framework\": \"torch\",\n\
          \    }\n\n    model_properties.path += \".json\"\n    with open(model_properties.path,\
          \ \"w\") as artifact_dump:\n        json.dump(properties, artifact_dump)\n\
          \n"
        image: python:3.11
pipelineInfo:
  description: Dense Neural Network CNN Image Detector based on YOLO
  name: yolo-custom-training-pipeline
root:
  dag:
    tasks:
      convert-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-convert-model
        dependentTasks:
        - train-model
        inputs:
          artifacts:
            finetuned_model:
              taskOutputArtifact:
                outputArtifactKey: finetuned_model
                producerTask: train-model
          parameters:
            data_dir:
              componentInputParameter: data_mount_path
        taskInfo:
          name: convert-model
      fetch-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-fetch-data
        inputs:
          parameters:
            dataset_name:
              componentInputParameter: dataset_name
            version:
              componentInputParameter: version
        taskInfo:
          name: fetch-data
      fetch-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-fetch-model
        inputs:
          parameters:
            hyperparameters:
              componentInputParameter: hyperparameters
            model_name:
              componentInputParameter: huggingface_repo
        taskInfo:
          name: fetch-model
      push-to-model-registry:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-push-to-model-registry
        dependentTasks:
        - convert-model
        inputs:
          parameters:
            author_name:
              componentInputParameter: author_name
            cluster_domain:
              componentInputParameter: cluster_domain
            data_path:
              componentInputParameter: data_mount_path
            model_name:
              componentInputParameter: model_name
            s3_deployment_name:
              componentInputParameter: s3_deployment_name
            s3_region:
              componentInputParameter: s3_region
            version:
              componentInputParameter: version
        taskInfo:
          name: push-to-model-registry
      train-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-model
        dependentTasks:
        - fetch-data
        - fetch-model
        - unzip-dataset
        - unzip-model
        inputs:
          artifacts:
            dataset:
              taskOutputArtifact:
                outputArtifactKey: dataset
                producerTask: fetch-data
            original_model:
              taskOutputArtifact:
                outputArtifactKey: original_model
                producerTask: fetch-model
          parameters:
            data_mount_path:
              componentInputParameter: data_mount_path
            hyperparameters:
              componentInputParameter: hyperparameters
        taskInfo:
          name: train-model
      unzip-dataset:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-unzip-dataset
        dependentTasks:
        - fetch-data
        inputs:
          artifacts:
            dataset:
              taskOutputArtifact:
                outputArtifactKey: dataset
                producerTask: fetch-data
          parameters:
            data_dir:
              componentInputParameter: data_mount_path
        taskInfo:
          name: unzip-dataset
      unzip-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-unzip-model
        dependentTasks:
        - fetch-model
        - unzip-dataset
        inputs:
          artifacts:
            model:
              taskOutputArtifact:
                outputArtifactKey: original_model
                producerTask: fetch-model
          parameters:
            data_dir:
              componentInputParameter: data_mount_path
        taskInfo:
          name: unzip-model
  inputDefinitions:
    parameters:
      author_name:
        parameterType: STRING
      cluster_domain:
        parameterType: STRING
      data_mount_path:
        parameterType: STRING
      dataset_name:
        parameterType: STRING
      huggingface_repo:
        parameterType: STRING
      hyperparameters:
        parameterType: STRUCT
      model_name:
        parameterType: STRING
      prod_flag:
        parameterType: BOOLEAN
      s3_deployment_name:
        parameterType: STRING
      s3_region:
        parameterType: STRING
      version:
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.12.2
---
platforms:
  kubernetes:
    deploymentSpec:
      executors:
        exec-convert-model:
          pvcMount:
          - constant: training
            mountPath: /data
            pvcNameParameter:
              runtimeValue:
                constant: training
        exec-fetch-data:
          secretAsEnv:
          - keyToEnv:
            - envVar: HF_HOME
              secretKey: HF_HOME
            - envVar: HF_TOKEN
              secretKey: HF_TOKEN
            secretName: huggingface-secret
            secretNameParameter:
              runtimeValue:
                constant: huggingface-secret
        exec-fetch-model:
          secretAsEnv:
          - keyToEnv:
            - envVar: KAGGLE_USERNAME
              secretKey: KAGGLE_USERNAME
            - envVar: KAGGLE_KEY
              secretKey: KAGGLE_KEY
            - envVar: KAGGLEHUB_CACHE
              secretKey: KAGGLEHUB_CACHE
            secretName: yolo-kaggle
            secretNameParameter:
              runtimeValue:
                constant: yolo-kaggle
        exec-push-to-model-registry:
          pvcMount:
          - constant: training
            mountPath: /data
            pvcNameParameter:
              runtimeValue:
                constant: training
          secretAsEnv:
          - keyToEnv:
            - envVar: AWS_S3_ENDPOINT
              secretKey: AWS_S3_ENDPOINT
            - envVar: AWS_ACCESS_KEY_ID
              secretKey: AWS_ACCESS_KEY_ID
            - envVar: AWS_SECRET_ACCESS_KEY
              secretKey: AWS_SECRET_ACCESS_KEY
            - envVar: AWS_S3_BUCKET
              secretKey: AWS_S3_BUCKET
            - envVar: AWS_DEFAULT_REGION
              secretKey: AWS_DEFAULT_REGION
            secretName: s3-models
            secretNameParameter:
              runtimeValue:
                constant: s3-models
        exec-train-model:
          pvcMount:
          - constant: training
            mountPath: /data
            pvcNameParameter:
              runtimeValue:
                constant: training
        exec-unzip-dataset:
          pvcMount:
          - constant: training
            mountPath: /data
            pvcNameParameter:
              runtimeValue:
                constant: training
        exec-unzip-model:
          pvcMount:
          - constant: training
            mountPath: /data
            pvcNameParameter:
              runtimeValue:
                constant: training
